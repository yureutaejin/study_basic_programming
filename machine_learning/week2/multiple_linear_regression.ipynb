{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([22. , 21.8, 21.2, 26.7, 24.7, 24.8, 25.5, 26.2, 29.7, 31.4, 33.1,\n",
       "       33.9, 39. , 39.4, 39.5, 40. ])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 실습과제_다중 선형 회귀 가설 함수 구현하기\n",
    "import numpy as np\n",
    "\n",
    "def prediction(X, theta):\n",
    "    \"\"\"다중 선형 회귀 가정 함수. 모든 데이터에 대한 예측 값을 numpy 배열로 리턴한다\"\"\"\n",
    "    # 코드를 쓰세요\n",
    "    return X@theta\n",
    "    \n",
    "    \n",
    "# 입력 변수\n",
    "house_size = np.array([1.0, 1.5, 1.8, 5, 2.0, 2.5, 3.0, 3.5, 4.0, 5.0, 6.0, 7.0, 8.0, 8.5, 9.0, 10.0])  # 집 크기\n",
    "distance_from_station = np.array([5, 4.6, 4.2, 3.9, 3.9, 3.6, 3.5, 3.4, 2.9, 2.8, 2.7, 2.3, 2.0, 1.8, 1.5, 1.0])  # 지하철역으로부터의 거리 (km)\n",
    "number_of_rooms = np.array([1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4])  # 방 수\n",
    "\n",
    "# 설계 행렬 X 정의\n",
    "X = np.array([\n",
    "    np.ones(16),\n",
    "    house_size,\n",
    "    distance_from_station,\n",
    "    number_of_rooms\n",
    "]).T\n",
    "\n",
    "# 파라미터 theta 값 정의\n",
    "theta = np.array([1, 2, 3, 4])\n",
    "\n",
    "prediction(X, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.11484521, 1.21120425, 0.18270523, 0.30060782])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 실습과제_다중 선형 회귀 경사 하강법 구현하기\n",
    "import numpy as np\n",
    "\n",
    "def prediction(X, theta):\n",
    "    \"\"\"다중 선형 회귀 가정 함수. 모든 데이터에 대한 예측 값을 numpy 배열로 리턴한다\"\"\"\n",
    "    # 전 과제 코드를 갖고 오세요\n",
    "    return X@theta\n",
    "    \n",
    "\n",
    "def gradient_descent(X, theta, y, iterations, alpha):\n",
    "    \"\"\"다중 선형 회귀 경사 하강법을 구현한 함수\"\"\"\n",
    "    m = len(X)  # 입력 변수 개수 저장\n",
    "    \n",
    "    for _ in range(iterations):\n",
    "        # 코드를 쓰세요\n",
    "        theta = theta - alpha/m*(X.T)@(prediction(X,theta) - y)\n",
    "        \n",
    "    return theta\n",
    "    \n",
    "\n",
    "# 입력 변수\n",
    "house_size = np.array([1.0, 1.5, 1.8, 5, 2.0, 2.5, 3.0, 3.5, 4.0, 5.0, 6.0, 7.0, 8.0, 8.5, 9.0, 10.0])  # 집 크기\n",
    "distance_from_station = np.array([5, 4.6, 4.2, 3.9, 3.9, 3.6, 3.5, 3.4, 2.9, 2.8, 2.7, 2.3, 2.0, 1.8, 1.5, 1.0])  # 지하철역으로부터의 거리 (km)\n",
    "number_of_rooms = np.array([1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4])  # 방 수\n",
    "\n",
    "# 목표 변수\n",
    "house_price = np.array([3, 3.2, 3.6 , 8, 3.4, 4.5, 5, 5.8, 6, 6.5, 9, 9, 10, 12, 13, 15])  # 집 가격\n",
    "\n",
    "# 설계 행렬 X 정의\n",
    "X = np.array([\n",
    "    np.ones(16),\n",
    "    house_size,\n",
    "    distance_from_station,\n",
    "    number_of_rooms\n",
    "]).T\n",
    "\n",
    "# 입력 변수 y 정의\n",
    "y = house_price\n",
    "\n",
    "# 파라미터 theta 초기화\n",
    "theta = np.array([0, 0, 0, 0])\n",
    "\n",
    "# 학습률 0.01로 100번 경사 하강\n",
    "theta = gradient_descent(X, theta, y, 100, 0.01)\n",
    "\n",
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.24706322,  1.30727421, -0.68881811, -0.8709494 ])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 실습과제_다중 선형 회귀 정규 방정식 구현하기\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def normal_equation(X, y):\n",
    "    \"\"\"설계 행렬 X와 목표 변수 벡터 y를 받아 정규 방정식으로 최적의 theta를 구하는 함수\"\"\"\n",
    "    # 코드를 쓰세요\n",
    "    return np.linalg.inv(X.T@X)@(X.T)@y # y.T\n",
    "    \n",
    "# 입력 변수\n",
    "house_size = np.array([1.0, 1.5, 1.8, 5, 2.0, 2.5, 3.0, 3.5, 4.0, 5.0, 6.0, 7.0, 8.0, 8.5, 9.0, 10.0])  # 집 크기\n",
    "distance_from_station = np.array([5, 4.6, 4.2, 3.9, 3.9, 3.6, 3.5, 3.4, 2.9, 2.8, 2.7, 2.3, 2.0, 1.8, 1.5, 1.0])  # 지하철역으로부터의 거리 (km)\n",
    "number_of_rooms = np.array([1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4])  # 방 수\n",
    "\n",
    "# 목표 변수\n",
    "house_price = np.array([3, 3.2, 3.6 , 8, 3.4, 4.5, 5, 5.8, 6, 6.5, 9, 9, 10, 12, 13, 15])  # 집 가격\n",
    "\n",
    "# 입력 변수 파라미터 X 정의\n",
    "X = np.array([\n",
    "    np.ones(16),\n",
    "    house_size,\n",
    "    distance_from_station,\n",
    "    number_of_rooms\n",
    "]).T\n",
    "\n",
    "# 입력 변수 y 정의\n",
    "y = house_price\n",
    "\n",
    "# 정규 방적식으로 theta 계산\n",
    "theta = normal_equation(X, y)\n",
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _boston_dataset:\n",
      "\n",
      "Boston house prices dataset\n",
      "---------------------------\n",
      "\n",
      "**Data Set Characteristics:**  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      ".. topic:: References\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# scikit-learn 데이터 준비\n",
    "from sklearn.datasets import load_boston\n",
    "boston_dataset = load_boston()\n",
    "print(boston_dataset.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "x = pd.DataFrame(boston_dataset.data, columns=boston_dataset.feature_names)\n",
    "y = pd.DataFrame(boston_dataset.target, columns = ['MEDV'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404, 13)\n",
      "(404, 1)\n",
      "(102, 13)\n",
      "(102, 1)\n"
     ]
    }
   ],
   "source": [
    "# scikit-learn으로 다중 선형 회귀 쉽게 하기\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size =0.2, random_state = 5)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.30799852e-01  4.94030235e-02  1.09535045e-03  2.70536624e+00\n",
      "  -1.59570504e+01  3.41397332e+00  1.11887670e-03 -1.49308124e+00\n",
      "   3.64422378e-01 -1.31718155e-02 -9.52369666e-01  1.17492092e-02\n",
      "  -5.94076089e-01]]\n",
      "[37.91248701]\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(x_train, y_train)\n",
    "print(model.coef_)\n",
    "print(model.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.5682920423032"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_prediction = model.predict(x_test)\n",
    "mean_squared_error(y_test, y_test_prediction) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54.60389611984443"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 실습과제_scikit-learn으로 당뇨 수치 예측하기\n",
    "# 필요한 라이브러리 import\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import pandas as pd  \n",
    "\n",
    "# 당뇨병 데이터 갖고 오기\n",
    "diabetes_dataset = datasets.load_diabetes()\n",
    "\n",
    "# 입력 변수를 사용하기 편하게 pandas dataframe으로 변환\n",
    "x = pd.DataFrame(diabetes_dataset.data, columns=diabetes_dataset.feature_names)\n",
    "\n",
    "# 목표 변수를 사용하기 편하게 pandas dataframe으로 변환\n",
    "y = pd.DataFrame(diabetes_dataset.target, columns=['diabetes'])\n",
    "\n",
    "# 코드를 쓰세요\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 5)\n",
    "model = LinearRegression()\n",
    "model.fit(x_train, y_train)\n",
    "y_test_predict = model.predict(x_test)\n",
    "\n",
    "\n",
    "# 평균 제곱 오차의 루트를 통해서 테스트 데이터에서의 모델 성능 판단\n",
    "mse = mean_squared_error(y_test, y_test_predict)\n",
    "\n",
    "mse ** 0.5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
